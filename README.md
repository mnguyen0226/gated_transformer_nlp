# Gated Transformers Implementation for NLP in Pytorch - Summer 2021
- This repo contain self-learning materials and project that I did to learn Transformers and NLP 
- I use Ben Trevett's [pytorch-seq2seq](https://github.com/bentrevett/pytorch-seq2seq) tutorials to learn RNN, GRU, LSTM, Transformers and later self-implement the latest Gated Transformers XL for NLP

# Transformers
- 1/ Gated Transformers XL
    - ![alt text](https://github.com/mnguyen0226/gated_transformers_nlp/blob/main/imgs/gated_transformers.png)
    - Architecture: Attention, GRU, Transformers XL
    - Paper: [Stabilizing Transformers for Reinforcement Learning](https://arxiv.org/abs/1910.067640)
    - [Code]()

- 2/ Classic Original Transformers
    - ![alt text](https://github.com/mnguyen0226/gated_transformers_nlp/blob/main/imgs/original_transformers.png)
    - Architecture: Attention, Transformers
    - Paper: [Attention Is All You Need](https://arxiv.org/abs/1706.03762)







